import keras
import numpy as np
import pickle
import json
import cv2
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import LSTM
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from keras import backend as K

imageModelPath = './ImageEmbedding.h5'
textModelPath = './TextEmbeddingL100.h5'
regularNNPath = './TextImageEmbedding.h5'
tokenPath = './tokenizerV2.pickle'
#Parameter : list of images
#Retur : list of vectors
def predictImageVector(images):
    images = np.asarray(images)
    images = images.astype('float32')
    images /= 255
    model = keras.models.load_model(imageModelPath)
    get_layer_output = K.function([model.layers[0].input,K.learning_phase()],[model.layers[14].output])
    vector_output = []
    for i in range(0,images.shape[0]):
        temp = get_layer_output([[images[i]],0])[0]
        vector_output.append(temp[0].tolist())
        if(i % 100 == 0):
            print("{} vector calculated".format(i))
    return vector_output

#Parameter : list of captions
#Return : list of vectors
def predictTextVector(texts):
    with open(tokenPath,'rb') as handle:
        Tokenizer=pickle.load(handle)
    max_caption_length=400
    texts = Tokenizer.texts_to_sequences(texts)
    texts = np.asarray(texts)
    texts = sequence.pad_sequences(texts, maxlen=max_caption_length)
    model = keras.models.load_model(textModelPath)
    get_layer_output = K.function([model.layers[0].input],[model.layers[1].output])
    vector_output = get_layer_output([texts])[0]
    return vector_output.tolist()

#Parameter: list of captions and list of images
#Return : list of feature vector which join two type vector 
def predictTextImageVector(texts,images):
    textVector = predictTextVector(texts)
    imageVector = predictImageVector(images)
    textImageVector = []
    if(len(textVector)!=len(imageVector)):
        print("Length of image list and length of text list should be equal! ")
    else:
        for i in range(0,len(textVector)):
            temp = textVector[i]+imageVector[i]
            textImageVector.append(temp)
    return textImageVector

#Parameter : list of captions and list of images
#Return : list of feature vector which is generated by a regular neural network
def predictTextImageVectorNN(texts,images):
    textVector = predictTextVector(texts)
    imageVector = predictImageVector(images)
    textImageVector = []
    model = keras.models.load_model(regularNNPath)
    get_layer_output = K.function([model.layers[0].input],[model.layers[0].output])
    if(len(textVector)!=len(imageVector)):
        print("Length of image list and length of text list should be equal! ")
    else:
        for i in range(0,len(textVector)):
            temp = textVector[i]+imageVector[i]
            textImageVector.append(temp)
    textImageVector = get_layer_output([textImageVector])[0]
    return textImageVector.tolist()
#Parameter : Json fileName or Json fileName list, when isList is setted true, the fileName is a list,
#            the file contains the images
#            the number of instances to load for each class
#Return : list of images, list of captions, list of metadata
def readDataFromJson(fileName,imagePath,isList = False,loadSize=100):
    data = []
    images = []
    texts = []
    if(isList):
        for path in fileName:
            with open(path) as f:
                temp = json.load(f)
                data += temp[0:loadSize]
                f.close()
    else:
        with open(fileName) as f:
            data = json.load(f)[0:loadSize]
    for i in range(0,len(data)):
        temp = cv2.imread(imagePath+data[i]['image_name'])
        images.append(temp)
        texts.append(data[i]['caption'])
    return images,texts,data

#Parameter: The saved JSON file name, metadata, the vector list, the dict to transfer label to class name
def saveToJson(fileName,metadata,vectors,labelToClass):
    beSaved = []
    for i in range(0,len(metadata)):
        temp = {}
        temp['image_name'] = metadata[i]['image_name']
        temp['label'] = metadata[i]['label']
        temp['caption'] = metadata[i]['caption']
        temp['class'] = labelToClass[str(metadata[i]['label'])]
        temp['vector'] = vectors[i]
        beSaved.append(temp)
    with open(fileName,'w') as f:
        json.dump(beSaved,f)